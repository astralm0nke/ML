{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "56b15191",
   "metadata": {},
   "source": [
    "## IMDB and Amazon Review: Text Classification with SpaCy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d10d958",
   "metadata": {},
   "source": [
    "3 Datasets. In each dataset, 0=negative sentiment, 1=positive sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4cbc2c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d598c579",
   "metadata": {},
   "source": [
    "## Import, Clean, Explore Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "e82ce80e",
   "metadata": {},
   "outputs": [],
   "source": [
    "yelp_dF = pd.read_csv('../Review_Classification/yelp_labelled.txt', sep='\\t')\n",
    "amazon_dF = pd.read_csv('../Review_Classification/amazon_cells_labelled.txt', sep='\\t')\n",
    "imdb_dF = pd.read_csv('../Review_Classification/imdb_labelled.txt', sep='\\t')\n",
    "##0-negative, 1-positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "2cae42a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            Wow... Loved this place.  1\n",
      "0                                 Crust is not good.  0\n",
      "1          Not tasty and the texture was just nasty.  0\n",
      "2  Stopped by during the late May bank holiday of...  1\n",
      "3  The selection on the menu was great and so wer...  1\n",
      "4     Now I am getting angry and I want my damn pho.  0\n",
      "  So there is no way for me to plug it in here in the US unless I go by a converter.  \\\n",
      "0                        Good case, Excellent value.                                   \n",
      "1                             Great for the jawbone.                                   \n",
      "2  Tied to charger for conversations lasting more...                                   \n",
      "3                                  The mic is great.                                   \n",
      "4  I have to jiggle the plug to get it to line up...                                   \n",
      "\n",
      "   0  \n",
      "0  1  \n",
      "1  1  \n",
      "2  0  \n",
      "3  1  \n",
      "4  0  \n",
      "  A very, very, very slow-moving, aimless movie about a distressed, drifting young man.    \\\n",
      "0  Not sure who was more lost - the flat characte...                                        \n",
      "1  Attempting artiness with black & white and cle...                                        \n",
      "2       Very little music or anything to speak of.                                          \n",
      "3  The best scene in the movie was when Gerardo i...                                        \n",
      "4  The rest of the movie lacks art, charm, meanin...                                        \n",
      "\n",
      "   0  \n",
      "0  0  \n",
      "1  0  \n",
      "2  0  \n",
      "3  1  \n",
      "4  0  \n"
     ]
    }
   ],
   "source": [
    "print(f'{yelp_dF.head()}\\n{amazon_dF.head()}\\n{imdb_dF.head()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "473e1a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Name Columns\n",
    "dataframes = [amazon_dF, imdb_dF, yelp_dF]\n",
    "column_names = ['Review', 'Sentiment']\n",
    "for dF in dataframes:\n",
    "    dF.columns = column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "d75767ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Good case, Excellent value.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Great for the jawbone.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tied to charger for conversations lasting more...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The mic is great.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I have to jiggle the plug to get it to line up...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review  Sentiment\n",
       "0                        Good case, Excellent value.          1\n",
       "1                             Great for the jawbone.          1\n",
       "2  Tied to charger for conversations lasting more...          0\n",
       "3                                  The mic is great.          1\n",
       "4  I have to jiggle the plug to get it to line up...          0"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amazon_dF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "b640d137",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Crust is not good.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Not tasty and the texture was just nasty.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Stopped by during the late May bank holiday of...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The selection on the menu was great and so wer...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Now I am getting angry and I want my damn pho.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review  Sentiment\n",
       "0                                 Crust is not good.          0\n",
       "1          Not tasty and the texture was just nasty.          0\n",
       "2  Stopped by during the late May bank holiday of...          1\n",
       "3  The selection on the menu was great and so wer...          1\n",
       "4     Now I am getting angry and I want my damn pho.          0"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yelp_dF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "19f4f5fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Not sure who was more lost - the flat characte...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Attempting artiness with black &amp; white and cle...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Very little music or anything to speak of.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The best scene in the movie was when Gerardo i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The rest of the movie lacks art, charm, meanin...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review  Sentiment\n",
       "0  Not sure who was more lost - the flat characte...          0\n",
       "1  Attempting artiness with black & white and cle...          0\n",
       "2       Very little music or anything to speak of.            0\n",
       "3  The best scene in the movie was when Gerardo i...          1\n",
       "4  The rest of the movie lacks art, charm, meanin...          0"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb_dF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "cf25f729",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((999, 2), (747, 2), (999, 2))"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amazon_dF.shape, imdb_dF.shape, yelp_dF.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "2b909cb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Review       0\n",
       " Sentiment    0\n",
       " dtype: int64,\n",
       " Review       0\n",
       " Sentiment    0\n",
       " dtype: int64,\n",
       " Review       0\n",
       " Sentiment    0\n",
       " dtype: int64)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amazon_dF.isna().sum(), imdb_dF.isna().sum(), yelp_dF.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b043e34",
   "metadata": {},
   "source": [
    "No missing values to worry about. Data is clean. No create one super dF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "40dcdb5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2745, 2)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_dF = yelp_dF.append([amazon_dF, imdb_dF], ignore_index=True)\n",
    "reviews_dF.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "186c8772",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    1385\n",
       "0    1360\n",
       "Name: Sentiment, dtype: int64"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_dF['Sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7e7673f",
   "metadata": {},
   "source": [
    "Balanced Dataset. Now apply some SpaCy techniques to remove stop words & punctuation and lemmatize."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2751ff04",
   "metadata": {},
   "source": [
    "## SpaCy: Stop Words & Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "57b3628f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "import string\n",
    "punct = string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "bce8d6cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['side',\n",
       " 'before',\n",
       " 'sometime',\n",
       " 'neither',\n",
       " 'both',\n",
       " 'formerly',\n",
       " 'became',\n",
       " 'hereby',\n",
       " 'is',\n",
       " 'just',\n",
       " 'no',\n",
       " 'less',\n",
       " 'the',\n",
       " 'those',\n",
       " 'was',\n",
       " 'or',\n",
       " 'without',\n",
       " 'yourselves',\n",
       " 'did',\n",
       " 'every',\n",
       " 'here',\n",
       " 'other',\n",
       " 'ten',\n",
       " 'another',\n",
       " 'his',\n",
       " 'per',\n",
       " 'yours',\n",
       " 'ca',\n",
       " 'about',\n",
       " 'below',\n",
       " 'how',\n",
       " 'at',\n",
       " 'itself',\n",
       " 'might',\n",
       " 'first',\n",
       " 'thereby',\n",
       " 'top',\n",
       " 'also',\n",
       " 'could',\n",
       " 'using',\n",
       " 'namely',\n",
       " 'we',\n",
       " 'bottom',\n",
       " 'us',\n",
       " 'again',\n",
       " 'off',\n",
       " 'herself',\n",
       " 'several',\n",
       " 'such',\n",
       " 'whose',\n",
       " 'back',\n",
       " 'nine',\n",
       " 'nowhere',\n",
       " 'their',\n",
       " 'and',\n",
       " 'three',\n",
       " 'above',\n",
       " 'not',\n",
       " 'who',\n",
       " 'latter',\n",
       " 'only',\n",
       " 'these',\n",
       " 'except',\n",
       " 'whoever',\n",
       " 'else',\n",
       " 'ourselves',\n",
       " 'within',\n",
       " 'quite',\n",
       " 'unless',\n",
       " 'into',\n",
       " 'myself',\n",
       " 'make',\n",
       " 'whether',\n",
       " 'indeed',\n",
       " 'her',\n",
       " 'should',\n",
       " 'than',\n",
       " 'so',\n",
       " 'down',\n",
       " 'hence',\n",
       " 'be',\n",
       " 'name',\n",
       " 're',\n",
       " 'as',\n",
       " 'made',\n",
       " 'yourself',\n",
       " 'fifty',\n",
       " 'put',\n",
       " 'still',\n",
       " 'themselves',\n",
       " 'everything',\n",
       " 'least',\n",
       " 'me',\n",
       " 'mostly',\n",
       " 'none',\n",
       " 'something',\n",
       " 'otherwise',\n",
       " 'whatever',\n",
       " 'either',\n",
       " 'does',\n",
       " 'already',\n",
       " 'anyway',\n",
       " 'between',\n",
       " 'show',\n",
       " 'therein',\n",
       " 'seem',\n",
       " 'whereas',\n",
       " 'afterwards',\n",
       " 'empty',\n",
       " 'fifteen',\n",
       " 'then',\n",
       " 'moreover',\n",
       " 'often',\n",
       " 'hereupon',\n",
       " 'next',\n",
       " 'own',\n",
       " 'too',\n",
       " 'eleven',\n",
       " 'twelve',\n",
       " 'were',\n",
       " 'our',\n",
       " 'nevertheless',\n",
       " 'are',\n",
       " 'cannot',\n",
       " 'with',\n",
       " 'they',\n",
       " 'once',\n",
       " 'this',\n",
       " 'further',\n",
       " 'more',\n",
       " 'say',\n",
       " 'take',\n",
       " 'few',\n",
       " 'my',\n",
       " 'now',\n",
       " 'there',\n",
       " 'forty',\n",
       " 'up',\n",
       " 'has',\n",
       " 'hereafter',\n",
       " 'though',\n",
       " 'which',\n",
       " 'an',\n",
       " 'former',\n",
       " 'from',\n",
       " 'whom',\n",
       " 'third',\n",
       " 'whenever',\n",
       " 'always',\n",
       " 'eight',\n",
       " 'various',\n",
       " 'call',\n",
       " 'across',\n",
       " 'amongst',\n",
       " 'twenty',\n",
       " 'wherever',\n",
       " 'keep',\n",
       " 'by',\n",
       " 'whence',\n",
       " 'ours',\n",
       " 'through',\n",
       " 'therefore',\n",
       " 'seemed',\n",
       " 'most',\n",
       " 'out',\n",
       " 'do',\n",
       " 'part',\n",
       " 'why',\n",
       " 'get',\n",
       " 'been',\n",
       " 'would',\n",
       " 'that',\n",
       " 'others',\n",
       " 'thence',\n",
       " 'everyone',\n",
       " 'had',\n",
       " 'nobody',\n",
       " 'am',\n",
       " 'throughout',\n",
       " 'himself',\n",
       " 'he',\n",
       " 'mine',\n",
       " 'somehow',\n",
       " 'front',\n",
       " 'anyone',\n",
       " 'doing',\n",
       " 'where',\n",
       " 'whereafter',\n",
       " 'someone',\n",
       " 'whereupon',\n",
       " 'anywhere',\n",
       " 'together',\n",
       " 'full',\n",
       " 'used',\n",
       " 'what',\n",
       " 'many',\n",
       " 'noone',\n",
       " 'go',\n",
       " 'six',\n",
       " 'move',\n",
       " 'all',\n",
       " 'until',\n",
       " 'wherein',\n",
       " 'amount',\n",
       " 'although',\n",
       " 'becomes',\n",
       " 'but',\n",
       " 'along',\n",
       " 'become',\n",
       " 'she',\n",
       " 'nor',\n",
       " 'hundred',\n",
       " 'please',\n",
       " 'ever',\n",
       " 'four',\n",
       " 'somewhere',\n",
       " 'elsewhere',\n",
       " 'see',\n",
       " 'i',\n",
       " 'your',\n",
       " 'must',\n",
       " 'seeming',\n",
       " 'if',\n",
       " 'due',\n",
       " 'may',\n",
       " 'to',\n",
       " 'have',\n",
       " 'serious',\n",
       " 'really',\n",
       " 'done',\n",
       " 'latterly',\n",
       " 'one',\n",
       " 'sixty',\n",
       " 'after',\n",
       " 'will',\n",
       " 'very',\n",
       " 'in',\n",
       " 'enough',\n",
       " 'much',\n",
       " 'upon',\n",
       " 'among',\n",
       " 'under',\n",
       " 'during',\n",
       " 'a',\n",
       " 'thru',\n",
       " 'thus',\n",
       " 'anyhow',\n",
       " 'its',\n",
       " 'whole',\n",
       " 'for',\n",
       " 'against',\n",
       " 'towards',\n",
       " 'rather',\n",
       " 'well',\n",
       " 'whither',\n",
       " 'give',\n",
       " 'beside',\n",
       " 'on',\n",
       " 'beforehand',\n",
       " 'beyond',\n",
       " 'onto',\n",
       " 'regarding',\n",
       " 'him',\n",
       " 'while',\n",
       " 'each',\n",
       " 'it',\n",
       " 'some',\n",
       " 'when',\n",
       " 'herein',\n",
       " 'over',\n",
       " 'seems',\n",
       " 'almost',\n",
       " 'toward',\n",
       " 'two',\n",
       " 'because',\n",
       " 'thereafter',\n",
       " 'same',\n",
       " 'can',\n",
       " 'any',\n",
       " 'everywhere',\n",
       " 'around',\n",
       " 'never',\n",
       " 'five',\n",
       " 'of',\n",
       " 'thereupon',\n",
       " 'whereby',\n",
       " 'anything',\n",
       " 'being',\n",
       " 'sometimes',\n",
       " 'last',\n",
       " 'via',\n",
       " 'even',\n",
       " 'behind',\n",
       " 'perhaps',\n",
       " 'nothing',\n",
       " 'yet',\n",
       " 'you',\n",
       " 'alone',\n",
       " 'them',\n",
       " 'becoming',\n",
       " 'since',\n",
       " 'meanwhile',\n",
       " 'however',\n",
       " 'besides',\n",
       " 'hers']"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words = list(STOP_WORDS)\n",
    "stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "28c9b770",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "def text_data_cleaner(sentence):\n",
    "    doc = nlp(sentence)\n",
    "    tokens = []\n",
    "    \n",
    "    for token in doc:\n",
    "        if token.lemma_ != '-PRON-':\n",
    "            temp = token.lemma_.lower().strip()\n",
    "        else:\n",
    "            temp = token.lower_\n",
    "        tokens.append(temp)\n",
    "        \n",
    "    cleaned_tokens = []\n",
    "    for token in tokens:\n",
    "        if token not in stop_words and token not in punct:\n",
    "            cleaned_tokens.append(token)\n",
    "    return cleaned_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a30e345",
   "metadata": {},
   "source": [
    "If root form of word (lemma) is not a pronoun, then we convert into lower form; if proper noun, then we directly take lower form because there's no lemma "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "b6aa1d78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hello', 'study', 'machine', 'learning', 'nlp', 'programmer']"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_data_cleaner('Hello, I am studying machine learning and NLP. I am a programmer.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8711e38",
   "metadata": {},
   "source": [
    "## Vectorization & Feature Engineering\n",
    "Using scikit-learn's text frequency-inverse document frequency vectorizer and linear support vector classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "efb054b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "7295e39a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(tokenizer=text_data_cleaner)\n",
    "clf = LinearSVC()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1840113a",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "ac68d0f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X = reviews_dF['Review']\n",
    "y = reviews_dF['Sentiment']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "626dbe7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "0681e857",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1839,), (906,))"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "b03fe40d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/finneassensiba/anaconda3/envs/nlp_course/lib/python3.7/site-packages/sklearn/utils/validation.py:209: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if LooseVersion(joblib_version) < '0.12':\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('tfidf', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.float64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,...ax_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0))])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_model = Pipeline([('tfidf', tfidf), ('clf', clf)])\n",
    "clf_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94cb20d3",
   "metadata": {},
   "source": [
    "## Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "527bc9db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "predictions = clf_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "0fd6a8b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.77      0.79       460\n",
      "           1       0.77      0.81      0.79       446\n",
      "\n",
      "   micro avg       0.79      0.79      0.79       906\n",
      "   macro avg       0.79      0.79      0.79       906\n",
      "weighted avg       0.79      0.79      0.79       906\n",
      "\n",
      "Accuracy: 79%\n",
      "Confusion Matrix:\n",
      "[[354 106]\n",
      " [ 85 361]]\n"
     ]
    }
   ],
   "source": [
    "print(f'{classification_report(y_test, predictions)}\\nAccuracy: {math.ceil(100*(accuracy_score(y_test, predictions)))}%\\nConfusion Matrix:\\n{confusion_matrix(y_test, predictions)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
